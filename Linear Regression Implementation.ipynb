{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Building a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building a linear regression model for any number of features, using the sum of the difference of the true and the predicted values as a loss function and gradient descent as an optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLinearRegression:\n",
    "    params = [];\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.params = [];\n",
    "        pass\n",
    "    \n",
    "    def cost(self, true, pred):\n",
    "        return np.sum(pred - true);\n",
    "        \n",
    "    def gradient_desc(self, X, y, iterations=None, learning_rate = 0.1):\n",
    "        if iterations is None:\n",
    "            current_cost = 0;\n",
    "            previous_cost = 0;\n",
    "            y_pred = self.predict(X);\n",
    "            current_cost = self.cost(y, y_pred);\n",
    "            while (np.abs(previous_cost - current_cost)) >= 0.001 :\n",
    "                previous_cost = current_cost;\n",
    "                \n",
    "                for i in range(X.shape[1]):\n",
    "                    self.params[i] = self.params[i] - learning_rate / X.shape[0] * np.sum((y_pred - y) * X[:,i]);\n",
    "                \n",
    "                y_pred = self.predict(X);\n",
    "                current_cost = self.cost(y, y_pred);\n",
    "        else:\n",
    "            for i in range(iterations):\n",
    "                y_pred = self.predict(X);\n",
    "                for i in range(X.shape[1]):\n",
    "                    self.params[i] = self.params[i] - learning_rate / X.shape[0] * np.sum((y_pred - y) * X[:,i]);\n",
    "    \n",
    "    def fit(self, X, y, iterations = None, learning_rate = 0.1, add_bias_term = True):\n",
    "        \"\"\"\n",
    "        -Fit a linear model with gradient descent. \n",
    "        -If no iterations number is passed, gradient descent will repeat until the change in cost function is < 0.001.\n",
    "        \"\"\"\n",
    "        if add_bias_term == True:\n",
    "            X = np.append(np.ones([X.shape[0], 1]), X, 1);\n",
    "            \n",
    "        if len(self.params) != X.shape[1]:\n",
    "            self.params = np.random.rand(X.shape[1], 1);\n",
    "        \n",
    "        self.gradient_desc(X, y, iterations, learning_rate);\n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict using the trained model.\n",
    "        \"\"\"\n",
    "        # Add bias term if the data shape mismatches the number of parameters.\n",
    "        if (X.shape[1] != len(self.params)):\n",
    "            X = np.append(np.ones([X.shape[0], 1]), X, 1);\n",
    "            \n",
    "        prediction = np.dot(np.transpose(self.params), np.transpose(X));\n",
    "        \n",
    "        return prediction;\n",
    "    \n",
    "    def params(self):\n",
    "        return self.params;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Generate some sample test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating data, which will be a function of 3 variables: $y = 5x_{1} + 3x_{2} + 2x_{3} + 9$ with some added noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(samples):\n",
    "    x = np.random.rand(samples, 3);\n",
    "    y = 5 * x[:,0] + 3 * x[:,1] + 2 * x[:,2] + 9;\n",
    "    noise = np.random.normal(0, 1, samples);\n",
    "    y = y + noise;\n",
    "    return x, y;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = generate_data(300);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test, y_test = generate_data(100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Compare to scikit-learn model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking how the model is performing on the training and testing set and comparing it to the sklearn model to see how mine is doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_lr = MyLinearRegression();\n",
    "my_lr.fit(x_train, y_train);\n",
    "train_predictions = my_lr.predict(x_train)[0];\n",
    "test_predictions = my_lr.predict(x_test)[0];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_lr = LinearRegression();\n",
    "sk_lr.fit(x_train, y_train, True);\n",
    "sk_train_pred = sk_lr.predict(x_train);\n",
    "sk_test_pred = sk_lr.predict(x_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My model:\n",
      "Coefficients:  [5.11562903 3.34761631 1.96525477]  Intercept:  8.679908055055748\n",
      "Train r2 score:  0.74645630985797\n",
      "Test r2 score:  0.7850681908719949\n"
     ]
    }
   ],
   "source": [
    "print(\"My model:\")\n",
    "print(\"Coefficients: \", np.transpose(my_lr.params)[0][1:], \" Intercept: \", np.transpose(my_lr.params)[0][0]);\n",
    "print(\"Train r2 score: \", r2_score(y_train, train_predictions));\n",
    "print(\"Test r2 score: \", r2_score(y_test, test_predictions));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sklearn model:\n",
      "Coefficients:  [5.10284578 3.33809439 1.94927766]  Intercept:  8.699324100478396\n",
      "Train r2 score:  0.7464653597244935\n",
      "Test r2 score:  0.7852865905779518\n"
     ]
    }
   ],
   "source": [
    "print(\"Sklearn model:\")\n",
    "print(\"Coefficients: \", sk_lr.coef_, \" Intercept: \", sk_lr.intercept_)\n",
    "print(\"Train r2 score: \", r2_score(y_train, sk_train_pred));\n",
    "print(\"Test r2 score: \", r2_score(y_test, sk_test_pred));"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
